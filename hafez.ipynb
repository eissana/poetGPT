{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "687rcbmW8HYB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MpKXwJSK8HYC"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    \"epochs\": 100,\n",
        "    \"learning_rate\": 3e-4,\n",
        "    \"batch_size\": 32,\n",
        "    \"embedding_dim\": 512,\n",
        "    \"nhead\": 8,\n",
        "    \"num_layers\": 3,\n",
        "    \"dropout\": 0.1,\n",
        "    \"block_size\": 13,\n",
        "    \"dim_feedforward\": 4,\n",
        "}\n",
        "load_model = False\n",
        "save_model = True\n",
        "model_filename = \"models/hafez.pt\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x3Hayx4Q8HYD"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\"\n",
        "    Self-attention head layer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, head_size, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.value = nn.Linear(embedding_dim, head_size, bias=False)\n",
        "        self.key = nn.Linear(embedding_dim, head_size, bias=False)\n",
        "        self.query = nn.Linear(embedding_dim, head_size, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, v, k, q, mask=None):\n",
        "        _, _, C = q.shape\n",
        "        value, key, query = self.value(v), self.key(k), self.query(q)\n",
        "        weights = query @ key.transpose(-2, -1) * C**-0.5\n",
        "\n",
        "        if mask is not None:\n",
        "            weights = weights.masked_fill(mask, float(\"-inf\"))\n",
        "\n",
        "        weights = F.softmax(weights, dim=-1)\n",
        "        weights = self.dropout(weights)\n",
        "\n",
        "        out = weights @ value\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiheadAttention(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        assert (\n",
        "            embedding_dim % num_heads == 0\n",
        "        ), f\"{embedding_dim=} must be divisible by {num_heads=}\"\n",
        "        head_size = embedding_dim // num_heads\n",
        "\n",
        "        self.ln = nn.LayerNorm(embedding_dim)\n",
        "        self.heads = nn.ModuleList(\n",
        "            [Head(embedding_dim, head_size, dropout) for _ in range(num_heads)]\n",
        "        )\n",
        "        self.proj = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, v, k, q, mask=None):\n",
        "        v, k, q = self.ln(v), self.ln(k), self.ln(q)\n",
        "        out = torch.cat([head(v, k, q, mask) for head in self.heads], dim=-1)\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, embedding_dim, dim_feedforward, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        # feed-forward network\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.LayerNorm(embedding_dim),\n",
        "            nn.Linear(embedding_dim, dim_feedforward * embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim_feedforward * embedding_dim, embedding_dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.ffn(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz, device):\n",
        "    return torch.tril(torch.ones(sz, sz).to(device)) == 0\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_heads, dim_feedforward, dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        # multi-head self attention with triangular mask. Nodes communicate only\n",
        "        # with previous nodes.\n",
        "        self.attn = MultiheadAttention(embedding_dim, num_heads, dropout)\n",
        "        self.ffn = FeedForward(embedding_dim, dim_feedforward)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        out = x\n",
        "        out = out + self.attn(out, out, out, mask)\n",
        "        out = out + self.ffn(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        num_layers,\n",
        "        block_size,\n",
        "        embedding_dim,\n",
        "        nhead,\n",
        "        dim_feedforward,\n",
        "        dropout,\n",
        "        device,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.emb = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.pos = nn.Embedding(block_size, embedding_dim)\n",
        "\n",
        "        self.decoders = nn.ModuleList(\n",
        "            [\n",
        "                DecoderBlock(\n",
        "                    embedding_dim,\n",
        "                    nhead,\n",
        "                    dim_feedforward,\n",
        "                    dropout,\n",
        "                )\n",
        "                for _ in range(num_layers)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.proj = nn.Linear(embedding_dim, vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, T = x.shape\n",
        "        positions = torch.arange(T).unsqueeze(0).to(self.device)\n",
        "        out = self.emb(x) + self.pos(positions)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        mask = generate_square_subsequent_mask(T, self.device)\n",
        "\n",
        "        for decoder in self.decoders:\n",
        "            out = decoder(out, mask)\n",
        "\n",
        "        out = self.proj(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0xZOkRED8HYE"
      },
      "outputs": [],
      "source": [
        "def get_tokenizer(filenames):\n",
        "    tk = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "    tk.enable_padding(pad_id=3)\n",
        "\n",
        "    trainer = BpeTrainer(special_tokens=[\"[SOS]\", \"[EOS]\", \"[UNK]\", \"[PAD]\"])\n",
        "    tk.train(filenames, trainer)\n",
        "\n",
        "    return tk\n",
        "\n",
        "\n",
        "def split(data, train_ratio=0.8, val_ratio=0.1):\n",
        "    ntrain = int(train_ratio * len(data))\n",
        "    nval = int(val_ratio * len(data))\n",
        "\n",
        "    train = data[:ntrain]\n",
        "    val = data[ntrain : ntrain + nval]\n",
        "    test = data[ntrain + nval :]\n",
        "\n",
        "    return train, val, test\n",
        "\n",
        "\n",
        "def get_batch(data, batch_size, block_size, device):\n",
        "    \"\"\"\n",
        "    Generates a batch of examples.\n",
        "    \"\"\"\n",
        "    indices = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in indices]).to(device)\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in indices]).to(device)\n",
        "\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def get_loss(logits, y, ignore_index):\n",
        "    \"\"\"\n",
        "    Computes cross-entropy loss, given logits and labels.\n",
        "    \"\"\"\n",
        "    B, T, C = logits.shape\n",
        "    # F.cross_entropy expects size C, (B, C), or (B, C, ...)\n",
        "    # logits shape is (B, T, C), so we flatten the first two dimensions.\n",
        "    return F.cross_entropy(\n",
        "        logits.view(B * T, C), y.reshape(B * T), ignore_index=ignore_index\n",
        "    )\n",
        "\n",
        "\n",
        "def generate(first_mesra, tk, model, device):\n",
        "    \"\"\"\n",
        "    Generates second mesra.\n",
        "    \"\"\"\n",
        "    token_ids = tk.encode(first_mesra).ids\n",
        "    x = torch.tensor(token_ids, dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "    while True:\n",
        "        logits = model(x)\n",
        "        # only consider the last logit\n",
        "        logits = logits[:, -1, :]\n",
        "        score = F.softmax(logits, dim=-1)\n",
        "        next_token_id = score.multinomial(1)\n",
        "        x = torch.cat((x, next_token_id), dim=1)\n",
        "        if \"\\n\" in tk.id_to_token(next_token_id):\n",
        "            break\n",
        "\n",
        "    x = x.view(-1)\n",
        "    return \" \".join([tk.id_to_token(t) for t in x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qluLmJVd9pJF"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data models\n",
        "!wget https://raw.githubusercontent.com/eissana/poetGPT/master/data/hafez.txt -O data/hafez.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txZ5fvrk8HYE",
        "outputId": "0cea5b75-83a6-4f56-ad6e-9dba9c2c9175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running on cpu\n",
            "\n",
            "\n",
            "\n",
            "vocab size: 30000\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"running on {device}\")\n",
        "\n",
        "text_file = \"data/hafez.txt\"\n",
        "\n",
        "tk = get_tokenizer([text_file])\n",
        "vocab_size = tk.get_vocab_size()\n",
        "print(f\"vocab size: {vocab_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHi4MDgV8HYF",
        "outputId": "3c976d21-f4c9-4144-e98d-2f54d2e4db9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model parameters: 511776\n"
          ]
        }
      ],
      "source": [
        "model = Transformer(\n",
        "    vocab_size=vocab_size,\n",
        "    num_layers=params[\"num_layers\"],\n",
        "    block_size=params[\"block_size\"],\n",
        "    embedding_dim=params[\"embedding_dim\"],\n",
        "    nhead=params[\"nhead\"],\n",
        "    dim_feedforward=params[\"dim_feedforward\"],\n",
        "    dropout=params[\"dropout\"],\n",
        "    device=device,\n",
        ").to(device)\n",
        "\n",
        "num_params = sum([p.nelement() for p in model.parameters()])\n",
        "print(f\"model parameters: {num_params}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sUL-O6DoCIV_"
      },
      "outputs": [],
      "source": [
        "with open(text_file) as f:\n",
        "    text = f.read()\n",
        "\n",
        "token_ids = torch.tensor(tk.encode(text).ids, dtype=torch.long)\n",
        "\n",
        "train, val, _ = split(token_ids, 0.9, 0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ouhq5MCwCRCz"
      },
      "outputs": [],
      "source": [
        "train_losses, val_losses = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LebjbDk88HYF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "first mesra: الا يا ايها الساقی ادر کاسا و ناولها\n",
            "epoch 1 / 10\n",
            "second mesra:\n",
            "يا ايها ال ساقی ادر  کاسا و  ناول ها مغبچه  طاووس  جان زير  ديدار  جان سوز\n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=params[\"learning_rate\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10\n",
        ")\n",
        "\n",
        "if load_model:\n",
        "    state = torch.load(model_filename)\n",
        "\n",
        "    model.load_state_dict(state[\"model\"])\n",
        "    optimizer.load_state_dict(state[\"optimizer\"])\n",
        "    scheduler.load_state_dict(state[\"scheduler\"])\n",
        "\n",
        "first_mesra = \"الا يا ايها الساقی ادر کاسا و ناولها\"\n",
        "print(f\"\\nfirst mesra: {first_mesra}\")\n",
        "\n",
        "for epoch in range(params[\"epochs\"]):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"epoch {epoch+1} / {params['epochs']}\")\n",
        "        second_mesra = generate(first_mesra, tk, model, device)\n",
        "        print(f\"second mesra:\\n{second_mesra}\")\n",
        "\n",
        "      x, y = get_batch(val, params[\"batch_size\"], params[\"block_size\"], device)\n",
        "\n",
        "      logits = model(x)\n",
        "      vloss = get_loss(logits, y, ignore_index=tk.token_to_id(\"[PAD]\"))\n",
        "      val_losses.append(vloss.item())\n",
        "\n",
        "    model.train()\n",
        "    x, y = get_batch(train, params[\"batch_size\"], params[\"block_size\"], device)\n",
        "\n",
        "    logits = model(x)\n",
        "    loss = get_loss(logits, y, ignore_index=tk.token_to_id(\"[PAD]\"))\n",
        "    train_losses.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "\n",
        "    if save_model:\n",
        "        checkpoint = {\n",
        "            \"model\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"scheduler\": scheduler.state_dict(),\n",
        "        }\n",
        "        torch.save(checkpoint, model_filename)\n",
        "\n",
        "    scheduler.step(train_losses[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tzZoM7fTAry_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss of a random model: 10.308952660644293\n",
            "final training loss: 10.964788627624511\n",
            "final validation loss: 10.87977409362793\n"
          ]
        }
      ],
      "source": [
        "print(f\"loss of a random model: {np.log(tk.get_vocab_size())}\")\n",
        "print(f\"final training loss: {np.mean(train_losses)}\")\n",
        "print(f\"final validation loss: {np.mean(val_losses)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMhDeAiUChPa"
      },
      "outputs": [],
      "source": [
        "eval_size = 10\n",
        "plt.plot(torch.tensor(train_losses).view(-1, eval_size).mean(axis=1));\n",
        "plt.plot(torch.tensor(val_losses).view(-1, eval_size).mean(axis=1));\n",
        "plt.legend(['training loss', 'validation loss']);"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
